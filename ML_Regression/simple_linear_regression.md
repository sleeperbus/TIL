# Regression fundamentals
## A case study in predicting house prices
## Regression fundamentals: data & model
## Regression fundamentals: the task
## Regression ML block diagram

# The simple linear regression model, its use, and interpretation
## The simple linear regression model
## The cost of using a given line
## Using the fitted line 
## Interpreting the fitted line

# An aside on optimization: one dimensional objectives
## Defining our least squares optimization objective
## Finding maxima or minima analytically
## Maximizing a 1d function: a worked example
## Finding the max via hill climbing
## Finding the min via hell descent
## Choosing stepsize and convergence criteria

# An aside on optimization: multidimensional objectives
## Gradients: derivatives in multiple dimensions
## Gradient descent: multidimensional hill descent
![1](https://d.pr/Y1ls+)
![2](https://d.pr/zDmM+)
![3](https://d.pr/Iby4+)
![4](https://d.pr/QspB+)

# Finding the least squares line 
## Computing the gradient of RSS
## Approach 1: closed-form soulution
## Optional reading: worked-out example for closed-form solution
## Approach 2: gradient descent
## Optional reading: worked-out example for gradient descent
## Comparing the approaches
![5](https://d.pr/DO8a+)
![6](https://d.pr/19RNE+)
![7](https://d.pr/d28T+)

# Discussion and summary of simple linear regression 
## Influence of high leverage points: exploring the data
## Influence of high leverage points: removing Center City
## Influence of high leverate points: removing high-end towns
## Asymmetric cos functions
## A breif recap
